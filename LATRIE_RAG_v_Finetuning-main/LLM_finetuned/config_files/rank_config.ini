[models]
LLM = ["TheBloke/Mistral-7B-Instruct-v0.2-GPTQ"]

[lora]
rank = [8, 50, 100]
lora_alpha = [32]
target_modules = [["q_proj"]]
lora_dropout = [0.05]

[quantization]
used = [1]

[train]
lr = [2e-4]
batch_size = [10]
num_epochs = [100]