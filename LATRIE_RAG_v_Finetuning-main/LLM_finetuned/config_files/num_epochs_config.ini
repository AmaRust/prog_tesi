[models]
LLM = ["TheBloke/Mistral-7B-Instruct-v0.2-GPTQ"]

[lora]
rank = [8]
lora_alpha = [32]
target_modules = [["q_proj"]]
lora_dropout = [0.05]

[quantization]
used = [0]

[train]
lr = [2e-4]
batch_size = [5]
num_epochs = [50, 100, 200, 500]