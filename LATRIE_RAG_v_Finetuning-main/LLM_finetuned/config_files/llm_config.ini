[models]
LLM = ["TheBloke/Mistral-7B-Instruct-v0.2-GPTQ", "microsoft/Phi-3-mini-128k-instruct"]

[lora]
rank = [8]
lora_alpha = [32]
target_modules = [["q_proj"]]
lora_dropout = [0.05]

[quantization]
used = [1]

[train]
lr = [2e-4]
batch_size = [5]
num_epochs = [200]